{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af2b7b7",
   "metadata": {},
   "source": [
    "**LOAD THE PDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f2c58628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-07-04T09:54:40+00:00', 'author': '', 'keywords': '', 'moddate': '2025-07-04T09:54:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': '', 'trapped': 'False', 'total_pages': 1, 'source': 'ALOK-RAI--22BEC010.pdf'}, page_content='ALOK RAI\\nMobile: +91-9151348969\\n\\nEducation\\n\\nEmail: 22bec010@iiitdmj.ac.in\\nLinkedIn: www.linkedin.com/in/alok-rai158\\nGitHub: github.com/ALOK158\\n\\n• Indian Institute of Information Technology, Design and Manufacturing\\n\\nBachelor of Technology - Electronics and Communication; CPI: 7.9\\n\\n• Sant Atulanand Convent School\\n\\n12th - 93.3%\\nExperience\\n\\n• Summer Intern\\n\\nMachine Learning Intern\\n\\nJabalpur, India\\nNov 2022 - July 2026\\n\\nVaranasi, India\\nApril 2020 - July 2021\\n\\nProfessor Aparajita Ojha\\nMay 2025 - Ongoing\\n\\n◦ Cancer Classification Using Gene Expression Data: Utilising a GenAI, Vision Models and DeepInsight framework\\n\\nto develop a pipeline for Cancer prediction from gene expression data.\\n\\n• Research Intern\\n\\nDr. Deep Prakash Samjdar\\nOct 2024 - May 2025\\n◦ Performance Analysis of Sn-based Perovskite Materials: Built ML models to predict solar cell metrics (Voc, Jsc,\\n\\nData Analyst Intern\\n\\nPCE, FF) of 11 materials, conducted EDA to uncover performance trends supporting next-gen solar cell research.\\n\\n• Summer Intern\\n\\nMachine Learning Intern\\n\\nIIITDM Jabalpur\\nMay 2024 - July 2024\\n\\n◦ Sign Language Detection Model: Developed a Convolutional Neural Network (CNN) model for real-time sign\\n\\nlanguage detection using Python and TensorFlow via collaborating with a team. Utilised Mediapipe and optimised model\\nperformance by fine-tuning hyperparameters to reduce computation time by 30%.\\n\\nSkills and Competencies\\n\\n3.1 Skills Summary\\n\\nProgramming Languages:Python(3+yrs), C++(3+ yrs), SQL, Matlab\\nML/NLP Frameworks: TensorFlow, PyTorch, Pandas, Scikit-learn, RAGs\\nVS Code, Google Colab, Hugging Face, LangChain\\nTools:\\nPower BI, Streamlit(2+yrs), Cadence(2+yrs), Arduino\\nOther:\\n\\nProjects\\n\\n• Transformer Language Model:\\n\\n◦ Implemented a GPT-style transformer-2.2 million parameters from scratch in PyTorch for autoregressive text\\n\\ngeneration.\\n\\n◦ Designed with Multi-head self-attention (6 heads), residual connections, and achieving a validation perplexity approx\\n\\n10 over 5000 iterations.\\n\\n◦ Tech Stack: PyTorch, Pandas, inspired by nanoGPT and Attention Is All You Need.\\n\\n• Feast-AI: APP\\n\\n◦ Achieved 85% accuracy on the DeepFood dataset, surpassing the original paper’s 77.4%, with a training time of ˜60\\n\\nmin compared to their 2-3 days.\\n\\n◦ A Food classification model capable of accurately identifying 101 types of food items.\\n\\n◦ Optimized computational efficiency by implementing mixed precision (float16 + float32).\\n\\n• EZE-Paragrapher:\\n\\n◦ Constructed an NLP classification system for research abstracts, enabling precise categorisation into Objective,\\n\\nMethods, Results, and Conclusion.\\n\\n◦ Trained on the SkimLit dataset to enhance literature review automation.\\n\\n◦ Combined BiDirectional LSTM for character-level vectorization with a Universal Sentence Encoder, improving\\n\\ncontextual understanding.\\n\\n◦ Implemented dropout layers to prevent overfitting, achieving an accuracy of 81.2%.\\n\\nVolunteer Experience\\n\\n• CO-Coordinator of Astronomy and Physics Society of College: Organised educational workshops and community\\nevents for the Astronomy and Physics Society, engaging over 200 participants in hands-on space exploration activities.\\n\\n• CAMPUS AMBASSADOR: I was also the Campus Ambassador of my college in Techkriti’24, IIT Kanpur.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "loader = PDFMinerLoader(\n",
    "    \"ALOK-RAI--22BEC010.pdf\",\n",
    "    mode=\"single\",\n",
    ")\n",
    "docs = loader.load()\n",
    "print(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd352aed",
   "metadata": {},
   "source": [
    "**PAGE CONTENT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "19ade358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALOK RAI\\nMobile: +91-9151348969\\n\\nEducation\\n\\nEmail: 22bec010@iiitdmj.ac.in\\nLinkedIn: www.linkedin.com/in/alok-rai158\\nGitHub: github.com/ALOK158\\n\\n• Indian Institute of Information Technology, Design and Manufacturing\\n\\nBachelor of Technology - Electronics and Communication; CPI: 7.9\\n\\n• Sant Atulanand Convent School\\n\\n12th - 93.3%\\nExperience\\n\\n• Summer Intern\\n\\nMachine Learning Intern\\n\\nJabalpur, India\\nNov 2022 - July 2026\\n\\nVaranasi, India\\nApril 2020 - July 2021\\n\\nProfessor Aparajita Ojha\\nMay 2025 - Ongoing\\n\\n◦ Cancer Classification Using Gene Expression Data: Utilising a GenAI, Vision Models and DeepInsight framework\\n\\nto develop a pipeline for Cancer prediction from gene expression data.\\n\\n• Research Intern\\n\\nDr. Deep Prakash Samjdar\\nOct 2024 - May 2025\\n◦ Performance Analysis of Sn-based Perovskite Materials: Built ML models to predict solar cell metrics (Voc, Jsc,\\n\\nData Analyst Intern\\n\\nPCE, FF) of 11 materials, conducted EDA to uncover performance trends supporting next-gen solar cell research.\\n\\n• Summer Intern\\n\\nMachine Learning Intern\\n\\nIIITDM Jabalpur\\nMay 2024 - July 2024\\n\\n◦ Sign Language Detection Model: Developed a Convolutional Neural Network (CNN) model for real-time sign\\n\\nlanguage detection using Python and TensorFlow via collaborating with a team. Utilised Mediapipe and optimised model\\nperformance by fine-tuning hyperparameters to reduce computation time by 30%.\\n\\nSkills and Competencies\\n\\n3.1 Skills Summary\\n\\nProgramming Languages:Python(3+yrs), C++(3+ yrs), SQL, Matlab\\nML/NLP Frameworks: TensorFlow, PyTorch, Pandas, Scikit-learn, RAGs\\nVS Code, Google Colab, Hugging Face, LangChain\\nTools:\\nPower BI, Streamlit(2+yrs), Cadence(2+yrs), Arduino\\nOther:\\n\\nProjects\\n\\n• Transformer Language Model:\\n\\n◦ Implemented a GPT-style transformer-2.2 million parameters from scratch in PyTorch for autoregressive text\\n\\ngeneration.\\n\\n◦ Designed with Multi-head self-attention (6 heads), residual connections, and achieving a validation perplexity approx\\n\\n10 over 5000 iterations.\\n\\n◦ Tech Stack: PyTorch, Pandas, inspired by nanoGPT and Attention Is All You Need.\\n\\n• Feast-AI: APP\\n\\n◦ Achieved 85% accuracy on the DeepFood dataset, surpassing the original paper’s 77.4%, with a training time of ˜60\\n\\nmin compared to their 2-3 days.\\n\\n◦ A Food classification model capable of accurately identifying 101 types of food items.\\n\\n◦ Optimized computational efficiency by implementing mixed precision (float16 + float32).\\n\\n• EZE-Paragrapher:\\n\\n◦ Constructed an NLP classification system for research abstracts, enabling precise categorisation into Objective,\\n\\nMethods, Results, and Conclusion.\\n\\n◦ Trained on the SkimLit dataset to enhance literature review automation.\\n\\n◦ Combined BiDirectional LSTM for character-level vectorization with a Universal Sentence Encoder, improving\\n\\ncontextual understanding.\\n\\n◦ Implemented dropout layers to prevent overfitting, achieving an accuracy of 81.2%.\\n\\nVolunteer Experience\\n\\n• CO-Coordinator of Astronomy and Physics Society of College: Organised educational workshops and community\\nevents for the Astronomy and Physics Society, engaging over 200 participants in hands-on space exploration activities.\\n\\n• CAMPUS AMBASSADOR: I was also the Campus Ambassador of my college in Techkriti’24, IIT Kanpur.']\n"
     ]
    }
   ],
   "source": [
    "page_contents = [doc.page_content for doc in docs]\n",
    "print(page_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bf95b9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALOK RAI\n",
      "Mobile: +91-9151348969\n",
      "\n",
      "Education\n",
      "\n",
      "Email: 22bec010@iiitdmj.ac.in\n",
      "LinkedIn: www.linkedin.com/in/alok-rai158\n",
      "GitHub: github.com/ALOK158\n",
      "\n",
      "• Indian Institute of Information Technology, Design and Manufacturing\n",
      "\n",
      "Bachelor of Technology - Electronics and Communication; CPI: 7.9\n",
      "\n",
      "• Sant Atulanand Convent School\n",
      "\n",
      "12th - 93.3%\n",
      "Experience\n",
      "\n",
      "• Summer Intern\n",
      "\n",
      "Machine Learning Intern\n",
      "\n",
      "Jabalpur, India\n",
      "Nov 2022 - July 2026\n",
      "\n",
      "Varanasi, India\n",
      "April 2020 - July 2021\n",
      "\n",
      "Professor Aparajita Ojha\n",
      "May 2025 - Ongoing\n",
      "\n",
      "◦ Cancer Classification Using Gene Expression Data: Utilising a GenAI, Vision Models and DeepInsight framework\n",
      "\n",
      "to develop a pipeline for Cancer prediction from gene expression data.\n",
      "\n",
      "• Research Intern\n",
      "\n",
      "Dr. Deep Prakash Samjdar\n",
      "Oct 2024 - May 2025\n",
      "◦ Performance Analysis of Sn-based Perovskite Materials: Built ML models to predict solar cell metrics (Voc, Jsc,\n",
      "\n",
      "Data Analyst Intern\n",
      "\n",
      "PCE, FF) of 11 materials, conducted EDA to uncover performance trends supporting next-gen solar cell research.\n",
      "\n",
      "• Summer Intern\n",
      "\n",
      "Machine Learning Intern\n",
      "\n",
      "IIITDM Jabalpur\n",
      "May 2024 - July 2024\n",
      "\n",
      "◦ Sign Language Detection Model: Developed a Convolutional Neural Network (CNN) model for real-time sign\n",
      "\n",
      "language detection using Python and TensorFlow via collaborating with a team. Utilised Mediapipe and optimised model\n",
      "performance by fine-tuning hyperparameters to reduce computation time by 30%.\n",
      "\n",
      "Skills and Competencies\n",
      "\n",
      "3.1 Skills Summary\n",
      "\n",
      "Programming Languages:Python(3+yrs), C++(3+ yrs), SQL, Matlab\n",
      "ML/NLP Frameworks: TensorFlow, PyTorch, Pandas, Scikit-learn, RAGs\n",
      "VS Code, Google Colab, Hugging Face, LangChain\n",
      "Tools:\n",
      "Power BI, Streamlit(2+yrs), Cadence(2+yrs), Arduino\n",
      "Other:\n",
      "\n",
      "Projects\n",
      "\n",
      "• Transformer Language Model:\n",
      "\n",
      "◦ Implemented a GPT-style transformer-2.2 million parameters from scratch in PyTorch for autoregressive text\n",
      "\n",
      "generation.\n",
      "\n",
      "◦ Designed with Multi-head self-attention (6 heads), residual connections, and achieving a validation perplexity approx\n",
      "\n",
      "10 over 5000 iterations.\n",
      "\n",
      "◦ Tech Stack: PyTorch, Pandas, inspired by nanoGPT and Attention Is All You Need.\n",
      "\n",
      "• Feast-AI: APP\n",
      "\n",
      "◦ Achieved 85% accuracy on the DeepFood dataset, surpassing the original paper’s 77.4%, with a training time of ˜60\n",
      "\n",
      "min compared to their 2-3 days.\n",
      "\n",
      "◦ A Food classification model capable of accurately identifying 101 types of food items.\n",
      "\n",
      "◦ Optimized computational efficiency by implementing mixed precision (float16 + float32).\n",
      "\n",
      "• EZE-Paragrapher:\n",
      "\n",
      "◦ Constructed an NLP classification system for research abstracts, enabling precise categorisation into Objective,\n",
      "\n",
      "Methods, Results, and Conclusion.\n",
      "\n",
      "◦ Trained on the SkimLit dataset to enhance literature review automation.\n",
      "\n",
      "◦ Combined BiDirectional LSTM for character-level vectorization with a Universal Sentence Encoder, improving\n",
      "\n",
      "contextual understanding.\n",
      "\n",
      "◦ Implemented dropout layers to prevent overfitting, achieving an accuracy of 81.2%.\n",
      "\n",
      "Volunteer Experience\n",
      "\n",
      "• CO-Coordinator of Astronomy and Physics Society of College: Organised educational workshops and community\n",
      "events for the Astronomy and Physics Society, engaging over 200 participants in hands-on space exploration activities.\n",
      "\n",
      "• CAMPUS AMBASSADOR: I was also the Campus Ambassador of my college in Techkriti’24, IIT Kanpur.\n"
     ]
    }
   ],
   "source": [
    "# Assuming docs is a list of Document objects\n",
    "page_contents = [doc.page_content for doc in docs]\n",
    "\n",
    "# Join all page contents into one complete text\n",
    "complete_text = \" \".join(page_contents)\n",
    "\n",
    "print(complete_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ac9bf93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7d55812a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "ALOK RAI\n",
      "Mobile: +91-9151348969\n",
      "\n",
      "Education\n",
      "\n",
      "Email: 22bec010@iiitdmj.ac.in\n",
      "LinkedIn: www.linkedin.com/in/alok-rai158\n",
      "GitHub: github.com/ALOK158\n",
      "\n",
      "• Indian Institute of Information Technology, Design and Manufacturing\n",
      "\n",
      "Bachelor of Technology - Electronics and Communication; CPI: 7.9\n",
      "\n",
      "• Sant Atulanand Convent School\n",
      "\n",
      "12th - 93.3%\n",
      "Experience\n",
      "\n",
      "• Summer Intern\n",
      "\n",
      "Machine Learning Intern\n",
      "\n",
      "Jabalpur, India\n",
      "Nov 2022 - July 2026\n",
      "\n",
      "Varanasi, India\n",
      "April 2020 - July 2021\n",
      "\n",
      "Professor Aparajita Ojha\n",
      "May 2025 - Ongoing\n",
      "\n",
      "◦ Cancer Classification Using Gene Expression Data: Utilising a GenAI, Vision Models and DeepInsight framework\n",
      "\n",
      "to develop a pipeline for Cancer prediction from gene expression data. • Research Intern\n",
      "\n",
      "Dr.\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Deep Prakash Samjdar\n",
      "Oct 2024 - May 2025\n",
      "◦ Performance Analysis of Sn-based Perovskite Materials: Built ML models to predict solar cell metrics (Voc, Jsc,\n",
      "\n",
      "Data Analyst Intern\n",
      "\n",
      "PCE, FF) of 11 materials, conducted EDA to uncover performance trends supporting next-gen solar cell research. • Summer Intern\n",
      "\n",
      "Machine Learning Intern\n",
      "\n",
      "IIITDM Jabalpur\n",
      "May 2024 - July 2024\n",
      "\n",
      "◦ Sign Language Detection Model: Developed a Convolutional Neural Network (CNN) model for real-time sign\n",
      "\n",
      "language detection using Python and TensorFlow via collaborating with a team. Utilised Mediapipe and optimised model\n",
      "performance by fine-tuning hyperparameters to reduce computation time by 30%. Skills and Competencies\n",
      "\n",
      "3.1 Skills Summary\n",
      "\n",
      "Programming Languages:Python(3+yrs), C++(3+ yrs), SQL, Matlab\n",
      "ML/NLP Frameworks: TensorFlow, PyTorch, Pandas, Scikit-learn, RAGs\n",
      "VS Code, Google Colab, Hugging Face, LangChain\n",
      "Tools:\n",
      "Power BI, Streamlit(2+yrs), Cadence(2+yrs), Arduino\n",
      "Other:\n",
      "\n",
      "Projects\n",
      "\n",
      "• Transformer Language Model:\n",
      "\n",
      "◦ Implemented a GPT-style transformer-2.2 million parameters from scratch in PyTorch for autoregressive text\n",
      "\n",
      "generation. ◦ Designed with Multi-head self-attention (6 heads), residual connections, and achieving a validation perplexity approx\n",
      "\n",
      "10 over 5000 iterations. ◦ Tech Stack: PyTorch, Pandas, inspired by nanoGPT and Attention Is All You Need. • Feast-AI: APP\n",
      "\n",
      "◦ Achieved 85% accuracy on the DeepFood dataset, surpassing the original paper’s 77.4%, with a training time of ˜60\n",
      "\n",
      "min compared to their 2-3 days. ◦ A Food classification model capable of accurately identifying 101 types of food items. ◦ Optimized computational efficiency by implementing mixed precision (float16 + float32). • EZE-Paragrapher:\n",
      "\n",
      "◦ Constructed an NLP classification system for research abstracts, enabling precise categorisation into Objective,\n",
      "\n",
      "Methods, Results, and Conclusion. ◦ Trained on the SkimLit dataset to enhance literature review automation. ◦ Combined BiDirectional LSTM for character-level vectorization with a Universal Sentence Encoder, improving\n",
      "\n",
      "contextual understanding. ◦ Implemented dropout layers to prevent overfitting, achieving an accuracy of 81.2%. Volunteer Experience\n",
      "\n",
      "• CO-Coordinator of Astronomy and Physics Society of College: Organised educational workshops and community\n",
      "events for the Astronomy and Physics Society, engaging over 200 participants in hands-on space exploration activities. • CAMPUS AMBASSADOR: I was also the Campus Ambassador of my college in Techkriti’24, IIT Kanpur.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load embeddings using Gemini Embedding model\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "# SemanticChunker splits based on semantic similarity\n",
    "splitter = SemanticChunker(embeddings=embedding_model, breakpoint_threshold_type=\"percentile\")\n",
    "\n",
    "# Perform semantic splitting\n",
    "chunks = splitter.split_text(complete_text)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\\n{chunk}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f94bcf",
   "metadata": {},
   "source": [
    "**Text-Splitting AND Vectorizing it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc952a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=100)\n",
    "texts = text_splitter.split_text(complete_text)\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "264efbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '4f4e440d-810a-4c47-88bb-82b16e18b4cd',\n",
       " 1: 'd3777771-f3f5-4185-8a57-f464572bd3b4',\n",
       " 2: 'bf72be2e-424e-4640-bdfa-f7bc6c977aa6',\n",
       " 3: '804ecac8-c364-4336-a14c-e89c357cb456',\n",
       " 4: 'a21f01de-3ff8-4f4c-a503-866496740aa4',\n",
       " 5: '94c83bfd-edb3-4560-b0bb-c675f149924a',\n",
       " 6: 'cb959af0-c4a0-4252-b372-132fde5ca828'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "# embedding_model is already defined above, so you can reuse it\n",
    "vector_store = FAISS.from_texts(texts, embedding_model)\n",
    "vector_store.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0ba23a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.get_by_ids(['820eab96-c96f-4291-9232-70d04b2c7414'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c225f314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"You are an resume helper that helps how well a job desciption is. For now based on job About the job\\nInternship Summary:\\n\\nWe're looking for enthusiastic and talented AI Interns passionate about coding to join our team. This internship offers a unique opportunity to gain hands-on experience by working on real-world projects, contributing to innovative solutions. You will play a crucial role in developing advanced AI solutions from data preparation to model deployment.\\n\\n\\nWhat You will Do:\\n\\nAs an AI Engineer Intern, you'll work closely with our team, contributing to various stages of the AI development lifecycle. Your responsibilities may include:\\nData Preparation & Annotation: Assist in collecting, cleaning, preprocessing, and annotating large datasets This will involve supporting robust OCR and HTR capabilities.\\nModel Experimentation & Evaluation: Conduct experiments to test, evaluate, and fine-tune AI models for accuracy, performance, and scalability.\\nInformation Extraction & Analysis: Contribute to the development and testing of features for highly accurate multilingual information extraction, retrieval, summarization, and enhanced pattern recognition from diverse, unstructured government documents.\\nLarge Language Model (LLM) Support: Support the team in evaluating, fine-tuning, and testing open-source LLMs for performance and suitability, ensuring they deeply understand government-specific terminology, policies, and contextual nuances in both English and Indian languages. \\nResearch & Exploration: Research the latest advancements, architectures, and techniques\\nPrototyping & Implementation: Help in building prototypes and integrating AI components, including those for conceptual predictive insights from forecasting models.\\nExperiment with prompt engineering techniques to optimize outputs from generative models.\\nExplore and implement techniques for controlling generated content and ensuring model safety/alignment.\\nDocumentation: Maintain clear and concise documentation of experiments, model development processes, and results.\\nCollaboration: Actively participate in team discussions, brainstorm new ideas, and collaborate with cross-functional teams to align AI solutions with business objectives.\\n\\nWho Can Apply:\\n\\nCurrently pursuing or recently completed a Bachelor's or Master's degree in Computer Science, Data Science, Artificial Intelligence, Machine Learning from a Tier 1 or Tier-2 Colleges / Autonomous Institutions.\\nStrong foundational understanding of core AI and Machine Learning concepts and algorithms.\\nSpecific interest in Natural Language Processing (NLP) and Large Language Models (LLMs) is highly preferred.\\nProficiency in at least one programming language, preferably Python is mandatory\\nFamiliarity with deep learning frameworks (e.g., TensorFlow) is a plus.\\nExcellent analytical and problem-solving skills, with a keen eye for detail in visual data and model outputs.\\nStrong communication and teamwork skills, with the ability to articulate technical concepts clearly.\\nA strong desire to learn, adapt, and contribute in a fast-paced environment focused on innovation., help to derive prompt to extarct all necessary information from retriver \")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"You are an resume helper that helps how well a job desciption is. For now based on job {desciption}, help to derive prompt to extarct all necessary information from retriver \")\n",
    "\n",
    "prompt_template.invoke({\"desciption\": '''About the job\n",
    "Internship Summary:\n",
    "\n",
    "We're looking for enthusiastic and talented AI Interns passionate about coding to join our team. This internship offers a unique opportunity to gain hands-on experience by working on real-world projects, contributing to innovative solutions. You will play a crucial role in developing advanced AI solutions from data preparation to model deployment.\n",
    "\n",
    "\n",
    "What You will Do:\n",
    "\n",
    "As an AI Engineer Intern, you'll work closely with our team, contributing to various stages of the AI development lifecycle. Your responsibilities may include:\n",
    "Data Preparation & Annotation: Assist in collecting, cleaning, preprocessing, and annotating large datasets This will involve supporting robust OCR and HTR capabilities.\n",
    "Model Experimentation & Evaluation: Conduct experiments to test, evaluate, and fine-tune AI models for accuracy, performance, and scalability.\n",
    "Information Extraction & Analysis: Contribute to the development and testing of features for highly accurate multilingual information extraction, retrieval, summarization, and enhanced pattern recognition from diverse, unstructured government documents.\n",
    "Large Language Model (LLM) Support: Support the team in evaluating, fine-tuning, and testing open-source LLMs for performance and suitability, ensuring they deeply understand government-specific terminology, policies, and contextual nuances in both English and Indian languages. \n",
    "Research & Exploration: Research the latest advancements, architectures, and techniques\n",
    "Prototyping & Implementation: Help in building prototypes and integrating AI components, including those for conceptual predictive insights from forecasting models.\n",
    "Experiment with prompt engineering techniques to optimize outputs from generative models.\n",
    "Explore and implement techniques for controlling generated content and ensuring model safety/alignment.\n",
    "Documentation: Maintain clear and concise documentation of experiments, model development processes, and results.\n",
    "Collaboration: Actively participate in team discussions, brainstorm new ideas, and collaborate with cross-functional teams to align AI solutions with business objectives.\n",
    " \n",
    "Who Can Apply:\n",
    "\n",
    "Currently pursuing or recently completed a Bachelor's or Master's degree in Computer Science, Data Science, Artificial Intelligence, Machine Learning from a Tier 1 or Tier-2 Colleges / Autonomous Institutions.\n",
    "Strong foundational understanding of core AI and Machine Learning concepts and algorithms.\n",
    "Specific interest in Natural Language Processing (NLP) and Large Language Models (LLMs) is highly preferred.\n",
    "Proficiency in at least one programming language, preferably Python is mandatory\n",
    "Familiarity with deep learning frameworks (e.g., TensorFlow) is a plus.\n",
    "Excellent analytical and problem-solving skills, with a keen eye for detail in visual data and model outputs.\n",
    "Strong communication and teamwork skills, with the ability to articulate technical concepts clearly.\n",
    "A strong desire to learn, adapt, and contribute in a fast-paced environment focused on innovation.'''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "223dce21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'AI Intern', 'company': None, 'location': None, 'summary': \"We're looking for enthusiastic and talented AI Interns passionate about coding to join our team. This internship offers a unique opportunity to gain hands-on experience by working on real-world projects, contributing to innovative solutions. You will play a crucial role in developing advanced AI solutions from data preparation to model deployment.\", 'responsibilities': ['Data Preparation & Annotation: Assist in collecting, cleaning, preprocessing, and annotating large datasets. This will involve supporting robust OCR and HTR capabilities.', 'Model Experimentation & Evaluation: Conduct experiments to test, evaluate, and fine-tune AI models for accuracy, performance, and scalability.', 'Information Extraction & Analysis: Contribute to the development and testing of features for highly accurate multilingual information extraction, retrieval, summarization, and enhanced pattern recognition from diverse, unstructured government documents.', 'Large Language Model (LLM) Support: Support the team in evaluating, fine-tuning, and testing open-source LLMs for performance and suitability, ensuring they deeply understand government-specific terminology, policies, and contextual nuances in both English and Indian languages.', 'Research & Exploration: Research the latest advancements, architectures, and techniques', 'Prototyping & Implementation: Help in building prototypes and integrating AI components, including those for conceptual predictive insights from forecasting models.', 'Experiment with prompt engineering techniques to optimize outputs from generative models.', 'Explore and implement techniques for controlling generated content and ensuring model safety/alignment.', 'Documentation: Maintain clear and concise documentation of experiments, model development processes, and results.', 'Collaboration: Actively participate in team discussions, brainstorm new ideas, and collaborate with cross-functional teams to align AI solutions with business objectives.'], 'required_skills': ['Strong foundational understanding of core AI and Machine Learning concepts and algorithms', 'Proficiency in at least one programming language, preferably Python'], 'preferred_skills': ['Specific interest in Natural Language Processing (NLP) and Large Language Models (LLMs)', 'Familiarity with deep learning frameworks (e.g., TensorFlow)', 'Excellent analytical and problem-solving skills, with a keen eye for detail in visual data and model outputs', 'Strong communication and teamwork skills, with the ability to articulate technical concepts clearly', 'A strong desire to learn, adapt, and contribute in a fast-paced environment focused on innovation'], 'education_requirements': \"Currently pursuing or recently completed a Bachelor's or Master's degree in Computer Science, Data Science, Artificial Intelligence, Machine Learning from a Tier 1 or Tier-2 Colleges / Autonomous Institutions.\", 'experience_level': 'Intern', 'Else': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "# ---------- 1. Prompt ----------\n",
    "job_jd_extraction_template = \"\"\"\n",
    "You are a resume-assistant that extracts structured data from job descriptions.\n",
    "\n",
    "Return ONLY valid JSON with these keys:\n",
    "- title                       (string or null)\n",
    "- company                     (string or null)\n",
    "- location                    (string or null)\n",
    "- summary                     (string)\n",
    "- responsibilities            (string[])\n",
    "- required_skills             (string[])\n",
    "- preferred_skills            (string[])\n",
    "- education_requirements      (string or null)\n",
    "- experience_level            (string or null)\n",
    "- Else                       (string or null)\n",
    "\n",
    "If a field is missing, use null or an empty list. In description, there can be multiple paragraphs, so you should extract the relevant information from the entire text and sometimes keys for JSON file will have synonyms or different names, so you should extract the relevant information from the entire text and sometimes keys for JSON file will have synonyms or different names.\n",
    "\n",
    "Job description:\n",
    "\\\"\\\"\\\"{description}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"description\"],\n",
    "    template=job_jd_extraction_template.strip()\n",
    ")\n",
    "\n",
    "# ---------- 2. LLM ----------\n",
    "# Gemini-Pro is the general-purpose chat model.\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",      # <- or \"gemini-pro-vision\" etc.\n",
    "    temperature=0.0          # deterministic extraction\n",
    ")\n",
    "\n",
    "# ---------- 3. Chain ----------\n",
    "chain = prompt | llm | SimpleJsonOutputParser()\n",
    "\n",
    "# ---------- 4. Run ----------\n",
    "jd = \"\"\" About the job\n",
    "Internship Summary:\n",
    "\n",
    "We're looking for enthusiastic and talented AI Interns passionate about coding to join our team. This internship offers a unique opportunity to gain hands-on experience by working on real-world projects, contributing to innovative solutions. You will play a crucial role in developing advanced AI solutions from data preparation to model deployment.\n",
    "\n",
    "\n",
    "What You will Do:\n",
    "\n",
    "As an AI Engineer Intern, you'll work closely with our team, contributing to various stages of the AI development lifecycle. Your responsibilities may include:\n",
    "Data Preparation & Annotation: Assist in collecting, cleaning, preprocessing, and annotating large datasets This will involve supporting robust OCR and HTR capabilities.\n",
    "Model Experimentation & Evaluation: Conduct experiments to test, evaluate, and fine-tune AI models for accuracy, performance, and scalability.\n",
    "Information Extraction & Analysis: Contribute to the development and testing of features for highly accurate multilingual information extraction, retrieval, summarization, and enhanced pattern recognition from diverse, unstructured government documents.\n",
    "Large Language Model (LLM) Support: Support the team in evaluating, fine-tuning, and testing open-source LLMs for performance and suitability, ensuring they deeply understand government-specific terminology, policies, and contextual nuances in both English and Indian languages. \n",
    "Research & Exploration: Research the latest advancements, architectures, and techniques\n",
    "Prototyping & Implementation: Help in building prototypes and integrating AI components, including those for conceptual predictive insights from forecasting models.\n",
    "Experiment with prompt engineering techniques to optimize outputs from generative models.\n",
    "Explore and implement techniques for controlling generated content and ensuring model safety/alignment.\n",
    "Documentation: Maintain clear and concise documentation of experiments, model development processes, and results.\n",
    "Collaboration: Actively participate in team discussions, brainstorm new ideas, and collaborate with cross-functional teams to align AI solutions with business objectives.\n",
    " \n",
    "Who Can Apply:\n",
    "\n",
    "Currently pursuing or recently completed a Bachelor's or Master's degree in Computer Science, Data Science, Artificial Intelligence, Machine Learning from a Tier 1 or Tier-2 Colleges / Autonomous Institutions.\n",
    "Strong foundational understanding of core AI and Machine Learning concepts and algorithms.\n",
    "Specific interest in Natural Language Processing (NLP) and Large Language Models (LLMs) is highly preferred.\n",
    "Proficiency in at least one programming language, preferably Python is mandatory\n",
    "Familiarity with deep learning frameworks (e.g., TensorFlow) is a plus.\n",
    "Excellent analytical and problem-solving skills, with a keen eye for detail in visual data and model outputs.\n",
    "Strong communication and teamwork skills, with the ability to articulate technical concepts clearly.\n",
    "A strong desire to learn, adapt, and contribute in a fast-paced environment focused on innovation.\n",
    " \"\"\"\n",
    "result = chain.invoke({\"description\": jd})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "52e247e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'AI Intern',\n",
       " 'company': None,\n",
       " 'location': None,\n",
       " 'summary': \"We're looking for enthusiastic and talented AI Interns passionate about coding to join our team. This internship offers a unique opportunity to gain hands-on experience by working on real-world projects, contributing to innovative solutions. You will play a crucial role in developing advanced AI solutions from data preparation to model deployment.\",\n",
       " 'responsibilities': ['Data Preparation & Annotation: Assist in collecting, cleaning, preprocessing, and annotating large datasets. This will involve supporting robust OCR and HTR capabilities.',\n",
       "  'Model Experimentation & Evaluation: Conduct experiments to test, evaluate, and fine-tune AI models for accuracy, performance, and scalability.',\n",
       "  'Information Extraction & Analysis: Contribute to the development and testing of features for highly accurate multilingual information extraction, retrieval, summarization, and enhanced pattern recognition from diverse, unstructured government documents.',\n",
       "  'Large Language Model (LLM) Support: Support the team in evaluating, fine-tuning, and testing open-source LLMs for performance and suitability, ensuring they deeply understand government-specific terminology, policies, and contextual nuances in both English and Indian languages.',\n",
       "  'Research & Exploration: Research the latest advancements, architectures, and techniques',\n",
       "  'Prototyping & Implementation: Help in building prototypes and integrating AI components, including those for conceptual predictive insights from forecasting models.',\n",
       "  'Experiment with prompt engineering techniques to optimize outputs from generative models.',\n",
       "  'Explore and implement techniques for controlling generated content and ensuring model safety/alignment.',\n",
       "  'Documentation: Maintain clear and concise documentation of experiments, model development processes, and results.',\n",
       "  'Collaboration: Actively participate in team discussions, brainstorm new ideas, and collaborate with cross-functional teams to align AI solutions with business objectives.'],\n",
       " 'required_skills': ['Strong foundational understanding of core AI and Machine Learning concepts and algorithms',\n",
       "  'Proficiency in at least one programming language, preferably Python'],\n",
       " 'preferred_skills': ['Specific interest in Natural Language Processing (NLP) and Large Language Models (LLMs)',\n",
       "  'Familiarity with deep learning frameworks (e.g., TensorFlow)',\n",
       "  'Excellent analytical and problem-solving skills, with a keen eye for detail in visual data and model outputs',\n",
       "  'Strong communication and teamwork skills, with the ability to articulate technical concepts clearly',\n",
       "  'A strong desire to learn, adapt, and contribute in a fast-paced environment focused on innovation'],\n",
       " 'education_requirements': \"Currently pursuing or recently completed a Bachelor's or Master's degree in Computer Science, Data Science, Artificial Intelligence, Machine Learning from a Tier 1 or Tier-2 Colleges / Autonomous Institutions.\",\n",
       " 'experience_level': 'Intern',\n",
       " 'Else': None}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b029f420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='804ecac8-c364-4336-a14c-e89c357cb456', metadata={}, page_content='Skills and Competencies\\n\\n3.1 Skills Summary\\n\\nProgramming Languages:Python(3+yrs), C++(3+ yrs), SQL, Matlab\\nML/NLP Frameworks: TensorFlow, PyTorch, Pandas, Scikit-learn, RAGs\\nVS Code, Google Colab, Hugging Face, LangChain\\nTools:\\nPower BI, Streamlit(2+yrs), Cadence(2+yrs), Arduino\\nOther:\\n\\nProjects\\n\\n• Transformer Language Model:\\n\\n◦ Implemented a GPT-style transformer-2.2 million parameters from scratch in PyTorch for autoregressive text\\n\\ngeneration.\\n\\n◦ Designed with Multi-head self-attention (6 heads), residual connections, and achieving a validation perplexity approx\\n\\n10 over 5000 iterations.'),\n",
       " Document(id='bf72be2e-424e-4640-bdfa-f7bc6c977aa6', metadata={}, page_content='• Summer Intern\\n\\nMachine Learning Intern\\n\\nIIITDM Jabalpur\\nMay 2024 - July 2024\\n\\n◦ Sign Language Detection Model: Developed a Convolutional Neural Network (CNN) model for real-time sign\\n\\nlanguage detection using Python and TensorFlow via collaborating with a team. Utilised Mediapipe and optimised model\\nperformance by fine-tuning hyperparameters to reduce computation time by 30%.\\n\\nSkills and Competencies\\n\\n3.1 Skills Summary'),\n",
       " Document(id='cb959af0-c4a0-4252-b372-132fde5ca828', metadata={}, page_content='• CAMPUS AMBASSADOR: I was also the Campus Ambassador of my college in Techkriti’24, IIT Kanpur.'),\n",
       " Document(id='94c83bfd-edb3-4560-b0bb-c675f149924a', metadata={}, page_content='Methods, Results, and Conclusion.\\n\\n◦ Trained on the SkimLit dataset to enhance literature review automation.\\n\\n◦ Combined BiDirectional LSTM for character-level vectorization with a Universal Sentence Encoder, improving\\n\\ncontextual understanding.\\n\\n◦ Implemented dropout layers to prevent overfitting, achieving an accuracy of 81.2%.\\n\\nVolunteer Experience\\n\\n• CO-Coordinator of Astronomy and Physics Society of College: Organised educational workshops and community\\nevents for the Astronomy and Physics Society, engaging over 200 participants in hands-on space exploration activities.'),\n",
       " Document(id='a21f01de-3ff8-4f4c-a503-866496740aa4', metadata={}, page_content='10 over 5000 iterations.\\n\\n◦ Tech Stack: PyTorch, Pandas, inspired by nanoGPT and Attention Is All You Need.\\n\\n• Feast-AI: APP\\n\\n◦ Achieved 85% accuracy on the DeepFood dataset, surpassing the original paper’s 77.4%, with a training time of ˜60\\n\\nmin compared to their 2-3 days.\\n\\n◦ A Food classification model capable of accurately identifying 101 types of food items.\\n\\n◦ Optimized computational efficiency by implementing mixed precision (float16 + float32).\\n\\n• EZE-Paragrapher:\\n\\n◦ Constructed an NLP classification system for research abstracts, enabling precise categorisation into Objective,'),\n",
       " Document(id='d3777771-f3f5-4185-8a57-f464572bd3b4', metadata={}, page_content='Varanasi, India\\nApril 2020 - July 2021\\n\\nProfessor Aparajita Ojha\\nMay 2025 - Ongoing\\n\\n◦ Cancer Classification Using Gene Expression Data: Utilising a GenAI, Vision Models and DeepInsight framework\\n\\nto develop a pipeline for Cancer prediction from gene expression data.\\n\\n• Research Intern\\n\\nDr. Deep Prakash Samjdar\\nOct 2024 - May 2025\\n◦ Performance Analysis of Sn-based Perovskite Materials: Built ML models to predict solar cell metrics (Voc, Jsc,\\n\\nData Analyst Intern\\n\\nPCE, FF) of 11 materials, conducted EDA to uncover performance trends supporting next-gen solar cell research.\\n\\n• Summer Intern')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Now based on {result} and  the stuff from resume extract all necessary information from retriver retrive the information from retriver \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7b03e",
   "metadata": {},
   "source": [
    "**MULTI-QUERY-RETIRVER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5f2ae85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_search_query(job: dict) -> str:\n",
    "    \"\"\"\n",
    "    Turn a structured job-post into a single keyword string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    job : dict\n",
    "        Must contain lists under some or all of these keys:\n",
    "        - \"responsibilities\"\n",
    "        - \"required_skills\"\n",
    "        - \"preferred_skills\"\n",
    "        Everything else is ignored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Comma-separated list with duplicates removed, e.g.\n",
    "        \"Python, TensorFlow, Data preparation, NLP, LLM fine-tuning\"\n",
    "    \"\"\"\n",
    "    # Collect lists; if the key is missing fall back to an empty list\n",
    "    resp    = job.get(\"responsibilities\", [])\n",
    "    req     = job.get(\"required_skills\", [])\n",
    "    pref    = job.get(\"preferred_skills\", [])\n",
    "\n",
    "    # Flatten + deduplicate while preserving order\n",
    "    seen, parts = set(), []\n",
    "    for item in resp + req + pref:\n",
    "        if isinstance(item, str) and item not in seen:\n",
    "            seen.add(item)\n",
    "            parts.append(item)\n",
    "\n",
    "    return \", \".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7320a486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Skills and Competencies\n",
      "\n",
      "3.1 Skills Summary\n",
      "\n",
      "Programming Languages:Python(3+yrs), C++(3+ yrs), SQL, Matlab\n",
      "ML/NLP Frameworks: TensorFlow, PyTorch, Pandas, Scikit-learn, RAGs\n",
      "VS Code, Google Colab, Hugging Face, LangChain\n",
      "Tools:\n",
      "Power BI, Streamlit(2+yrs), Cadence(2+yrs), Arduino\n",
      "Other:\n",
      "\n",
      "Projects\n",
      "\n",
      "• Transformer Language Model:\n",
      "\n",
      "◦ Implemented a GPT-style transformer-2.2 million parameters from scratch in PyTorch for autoregressive text\n",
      "\n",
      "generation.\n",
      "\n",
      "◦ Designed with Multi-head self-attention (6 heads), residual connections, and achieving a validation perplexity approx\n",
      "\n",
      "10 over 5000 iterations.\n",
      "[Document(id='804ecac8-c364-4336-a14c-e89c357cb456', metadata={}, page_content='Skills and Competencies\\n\\n3.1 Skills Summary\\n\\nProgramming Languages:Python(3+yrs), C++(3+ yrs), SQL, Matlab\\nML/NLP Frameworks: TensorFlow, PyTorch, Pandas, Scikit-learn, RAGs\\nVS Code, Google Colab, Hugging Face, LangChain\\nTools:\\nPower BI, Streamlit(2+yrs), Cadence(2+yrs), Arduino\\nOther:\\n\\nProjects\\n\\n• Transformer Language Model:\\n\\n◦ Implemented a GPT-style transformer-2.2 million parameters from scratch in PyTorch for autoregressive text\\n\\ngeneration.\\n\\n◦ Designed with Multi-head self-attention (6 heads), residual connections, and achieving a validation perplexity approx\\n\\n10 over 5000 iterations.'), Document(id='bf72be2e-424e-4640-bdfa-f7bc6c977aa6', metadata={}, page_content='• Summer Intern\\n\\nMachine Learning Intern\\n\\nIIITDM Jabalpur\\nMay 2024 - July 2024\\n\\n◦ Sign Language Detection Model: Developed a Convolutional Neural Network (CNN) model for real-time sign\\n\\nlanguage detection using Python and TensorFlow via collaborating with a team. Utilised Mediapipe and optimised model\\nperformance by fine-tuning hyperparameters to reduce computation time by 30%.\\n\\nSkills and Competencies\\n\\n3.1 Skills Summary'), Document(id='94c83bfd-edb3-4560-b0bb-c675f149924a', metadata={}, page_content='Methods, Results, and Conclusion.\\n\\n◦ Trained on the SkimLit dataset to enhance literature review automation.\\n\\n◦ Combined BiDirectional LSTM for character-level vectorization with a Universal Sentence Encoder, improving\\n\\ncontextual understanding.\\n\\n◦ Implemented dropout layers to prevent overfitting, achieving an accuracy of 81.2%.\\n\\nVolunteer Experience\\n\\n• CO-Coordinator of Astronomy and Physics Society of College: Organised educational workshops and community\\nevents for the Astronomy and Physics Society, engaging over 200 participants in hands-on space exploration activities.'), Document(id='d3777771-f3f5-4185-8a57-f464572bd3b4', metadata={}, page_content='Varanasi, India\\nApril 2020 - July 2021\\n\\nProfessor Aparajita Ojha\\nMay 2025 - Ongoing\\n\\n◦ Cancer Classification Using Gene Expression Data: Utilising a GenAI, Vision Models and DeepInsight framework\\n\\nto develop a pipeline for Cancer prediction from gene expression data.\\n\\n• Research Intern\\n\\nDr. Deep Prakash Samjdar\\nOct 2024 - May 2025\\n◦ Performance Analysis of Sn-based Perovskite Materials: Built ML models to predict solar cell metrics (Voc, Jsc,\\n\\nData Analyst Intern\\n\\nPCE, FF) of 11 materials, conducted EDA to uncover performance trends supporting next-gen solar cell research.\\n\\n• Summer Intern'), Document(id='a21f01de-3ff8-4f4c-a503-866496740aa4', metadata={}, page_content='10 over 5000 iterations.\\n\\n◦ Tech Stack: PyTorch, Pandas, inspired by nanoGPT and Attention Is All You Need.\\n\\n• Feast-AI: APP\\n\\n◦ Achieved 85% accuracy on the DeepFood dataset, surpassing the original paper’s 77.4%, with a training time of ˜60\\n\\nmin compared to their 2-3 days.\\n\\n◦ A Food classification model capable of accurately identifying 101 types of food items.\\n\\n◦ Optimized computational efficiency by implementing mixed precision (float16 + float32).\\n\\n• EZE-Paragrapher:\\n\\n◦ Constructed an NLP classification system for research abstracts, enabling precise categorisation into Objective,'), Document(id='4f4e440d-810a-4c47-88bb-82b16e18b4cd', metadata={}, page_content='ALOK RAI\\nMobile: +91-9151348969\\n\\nEducation\\n\\nEmail: 22bec010@iiitdmj.ac.in\\nLinkedIn: www.linkedin.com/in/alok-rai158\\nGitHub: github.com/ALOK158\\n\\n• Indian Institute of Information Technology, Design and Manufacturing\\n\\nBachelor of Technology - Electronics and Communication; CPI: 7.9\\n\\n• Sant Atulanand Convent School\\n\\n12th - 93.3%\\nExperience\\n\\n• Summer Intern\\n\\nMachine Learning Intern\\n\\nJabalpur, India\\nNov 2022 - July 2026\\n\\nVaranasi, India\\nApril 2020 - July 2021\\n\\nProfessor Aparajita Ojha\\nMay 2025 - Ongoing'), Document(id='cb959af0-c4a0-4252-b372-132fde5ca828', metadata={}, page_content='• CAMPUS AMBASSADOR: I was also the Campus Ambassador of my college in Techkriti’24, IIT Kanpur.')]\n"
     ]
    }
   ],
   "source": [
    "# --- 0. prerequisites ---------------------------------------------------------\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# --- 1. base retriever --------------------------------------------------------\n",
    "# pull (for example) the 2 most similar chunks for *each* query\n",
    "base_retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 7}\n",
    ")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI   # make sure this import matches your package version\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",   # <- correct kwarg\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "# --- 3. wrap in a Multi-Query retriever --------------------------------------\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "        retriever   = base_retriever,   # your existing retriever\n",
    "        llm         = llm\n",
    ")\n",
    "\n",
    "# 4. build search query from job post\n",
    "search_query = build_search_query(result)\n",
    "\n",
    "docs =multi_query_retriever.get_relevant_documents(search_query)\n",
    "\n",
    "# --- 4. use it like any other retriever --------------------------------------\n",
    "\n",
    "print(len(docs), docs[0].page_content)\n",
    "print(docs)\n",
    "\n",
    "# or plug it straight into a QA / conversation chain\n",
    "# from langchain.chains import ConversationalRetrievalChain\n",
    "# qa_chain = ConversationalRetrievalChain.from_llm(llm, multi_query_retriever)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b29e654",
   "metadata": {},
   "source": [
    "**PROMPT TO COMPARE JOB DESCRIPTION AND THE RESUME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a8f68eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"matches\": [\n",
      "    \"The resume shows proficiency in Python and experience with TensorFlow, both required skills.\",\n",
      "    \"The candidate has experience with NLP, including building a transformer language model and working on a food classification model, aligning with the preferred skills and responsibilities.\",\n",
      "    \"The resume demonstrates experience in model development, evaluation, and optimization, including hyperparameter tuning and techniques to reduce computation time.\",\n",
      "    \"The candidate's projects showcase experience in various aspects of AI development, such as data preprocessing, model training, and performance analysis.\",\n",
      "    \"The candidate's internship experience at IIITDM Jabalpur aligns with the required education level.\"\n",
      "  ],\n",
      "  \"gaps\": [\n",
      "    \"The resume does not explicitly mention experience with large language models (LLMs) beyond building a transformer model, which is a key preferred skill and responsibility.\",\n",
      "    \"There is no mention of experience with multilingual information extraction or handling government-specific terminology, which are crucial aspects of the internship.\",\n",
      "    \"The resume lacks explicit demonstration of experience in data annotation, a key responsibility of the internship.\",\n",
      "    \"The resume does not showcase experience with prompt engineering or techniques for controlling generated content and ensuring model safety/alignment.\",\n",
      "    \"While the candidate has experience with several deep learning frameworks, the resume does not explicitly mention experience with other tools or technologies that might be used in the internship.\"\n",
      "  ],\n",
      "  \"overall_fit\": \"While the candidate possesses some relevant skills and experience in AI and NLP, the lack of specific experience with LLMs, multilingual information extraction, data annotation, and model safety makes them a weak fit for this AI internship.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1-- LLM instance\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
    "\n",
    "# 2-- prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a career-matching assistant. \"\n",
    "     \"Use ONLY the resume snippets provided to judge the fit.\"),\n",
    "    (\"user\", \"Job description (JSON):\\n{job_json}\"),\n",
    "    (\"user\", \"Resume snippets:\\n{snippets}\"),\n",
    "    (\"user\",\n",
    "     \"Return a JSON with keys:\\n\"\n",
    "     \"  - matches  (bullet points where the resume meets the job)\\n\"\n",
    "     \"  - gaps     (bullet points where the resume is missing something)\\n\"\n",
    "     \"  - overall_fit (one-sentence conclusion)-- be very strict in your assessment!\"),\n",
    "])\n",
    "\n",
    "# 3-- combine template + LLM  -> runnable chain\n",
    "chain = prompt | llm          # equivalent to RunnableSequence(prompt, llm)\n",
    "\n",
    "# 4-- variables you collected earlier\n",
    "variables = {\n",
    "    \"job_json\": result,          # dict or JSON string\n",
    "    \"snippets\": docs                # \"\\n---\\n\".join(d.page_content for d in docs)\n",
    "}\n",
    "\n",
    "# 5-- run the chain\n",
    "answer = chain.invoke(variables)        # returns an LLM message object\n",
    "print(answer.content)                   # or just `print(answer)` depending on version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1fc77",
   "metadata": {},
   "source": [
    "**CHAINING UP THE WHOLE PROCESS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "49e9fa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n{\\n  \"matches\": [\\n    \"The resume demonstrates experience with TensorFlow and PyTorch, as well as other relevant tools like Hugging Face and LangChain.\",\\n    \"The candidate has multiple projects showcasing experience in model development and optimization, including a Transformer Language Model and a food classification model.\",\\n    \"The resume indicates experience with NLP through projects like the Transformer Language Model and EZE-Paragrapher.\"\\n  ],\\n  \"gaps\": [\\n    \"The resume does not mention experience with data preparation and annotation.\",\\n    \"There is no mention of experience with multilingual information extraction or working with government documents.\",\\n    \"The resume lacks explicit demonstration of experience with LLMs beyond general NLP experience.\",\\n    \"The candidate\\'s education is not explicitly stated as being from a Tier 1 or Tier 2 college.\",\\n    \"The resume does not highlight experience with prompt engineering or model safety/alignment techniques.\"\\n  ],\\n  \"overall_fit\": \"Despite some relevant skills and project experience, the candidate\\'s resume lacks crucial experience in data preparation, LLM work, and specific application areas, making them a poor fit for the AI Intern role.\"\\n}\\n```' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []} id='run--422b3671-f429-4c1a-94c1-31deec7b7d6a-0' usage_metadata={'input_tokens': 1407, 'output_tokens': 248, 'total_tokens': 1655, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 5. comparison prompt\n",
    "comparison = prompt | llm\n",
    "result = comparison.invoke({\"job_json\": result,\n",
    "                            \"snippets\": \"\\n---\\n\".join(d.page_content for d in docs)})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
