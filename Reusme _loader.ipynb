{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7db5b0",
   "metadata": {},
   "source": [
    "**Processing and Creating Vector Store to load the content of PDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09c273f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "#PDF--PDF LOADER--LLM(structured again)-- vector dDATA_BASE---\n",
    "\n",
    "# CONERTING PDF LOADER INTO RUNABLE\n",
    "import os\n",
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "\n",
    "def load_pdf_documents(file_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    A function to load a PDF file using PDFMinerLoader.\n",
    "    It takes a file path string and returns a list of Document objects.\n",
    "    \"\"\"\n",
    "    # Check if the file exists to provide a better error message\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file '{file_path}' was not found.\")\n",
    "        \n",
    "    loader = PDFMinerLoader(\n",
    "        file_path,\n",
    "        mode=\"single\",  # Loads all pages into one Document object\n",
    "    )\n",
    "    # The loader returns a list of documents\n",
    "    docs = loader.load()\n",
    "    # Assuming docs is a list of Document objects\n",
    "    page_contents = [doc.page_content for doc in docs]\n",
    "\n",
    "    # Join all page contents into one complete text\n",
    "    complete_text = \" \".join(page_contents)\n",
    "\n",
    "    return complete_text\n",
    "\n",
    "# Create a runnable from the loading function.\n",
    "pdf_loader_runnable = RunnableLambda(load_pdf_documents)\n",
    "pdf=pdf_loader_runnable.invoke(\"ALOK-RAI--22BEC010.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#splitter_text=pdf | texts\n",
    "# NOW WE GET OUR PDF----Its time to genrate its embeddings and store it in vector database\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "'''splitter = SemanticChunker(\n",
    "    embeddings=embedding_model,\n",
    "    breakpoint_threshold_type=\"percentile\"\n",
    ")'''\n",
    "\n",
    "## Converting the text splitter into a runnable\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "\n",
    "##--- Change the spillter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=100)\n",
    "texts = text_splitter.split_text(pdf)\n",
    "print(len(texts))\n",
    "\n",
    "\n",
    "##---This was whole for reume part--\n",
    "\n",
    "\"\"\"Creates a FAISS vector store from texts and returns a retriever.\"\"\"\n",
    "vector_store = FAISS.from_texts(texts, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e42ae7",
   "metadata": {},
   "source": [
    "**JoB -DESCRIPTION CHAIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93673682",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = \"\"\" About the job\n",
    "Internship Summary:\n",
    "\n",
    "We're looking for enthusiastic and talented AI Interns passionate about coding to join our team. This internship offers a unique opportunity to gain hands-on experience by working on real-world projects, contributing to innovative solutions. You will play a crucial role in developing advanced AI solutions from data preparation to model deployment.\n",
    "\n",
    "\n",
    "What You will Do:\n",
    "\n",
    "As an AI Engineer Intern, you'll work closely with our team, contributing to various stages of the AI development lifecycle. Your responsibilities may include:\n",
    "Data Preparation & Annotation: Assist in collecting, cleaning, preprocessing, and annotating large datasets This will involve supporting robust OCR and HTR capabilities.\n",
    "Model Experimentation & Evaluation: Conduct experiments to test, evaluate, and fine-tune AI models for accuracy, performance, and scalability.\n",
    "Information Extraction & Analysis: Contribute to the development and testing of features for highly accurate multilingual information extraction, retrieval, summarization, and enhanced pattern recognition from diverse, unstructured government documents.\n",
    "Large Language Model (LLM) Support: Support the team in evaluating, fine-tuning, and testing open-source LLMs for performance and suitability, ensuring they deeply understand government-specific terminology, policies, and contextual nuances in both English and Indian languages. \n",
    "Research & Exploration: Research the latest advancements, architectures, and techniques\n",
    "Prototyping & Implementation: Help in building prototypes and integrating AI components, including those for conceptual predictive insights from forecasting models.\n",
    "Experiment with prompt engineering techniques to optimize outputs from generative models.\n",
    "Explore and implement techniques for controlling generated content and ensuring model safety/alignment.\n",
    "Documentation: Maintain clear and concise documentation of experiments, model development processes, and results.\n",
    "Collaboration: Actively participate in team discussions, brainstorm new ideas, and collaborate with cross-functional teams to align AI solutions with business objectives.\n",
    " \n",
    "Who Can Apply:\n",
    "\n",
    "Currently pursuing or recently completed a Bachelor's or Master's degree in Computer Science, Data Science, Artificial Intelligence, Machine Learning from a Tier 1 or Tier-2 Colleges / Autonomous Institutions.\n",
    "Strong foundational understanding of core AI and Machine Learning concepts and algorithms.\n",
    "Specific interest in Natural Language Processing (NLP) and Large Language Models (LLMs) is highly preferred.\n",
    "Proficiency in at least one programming language, preferably Python is mandatory\n",
    "Familiarity with deep learning frameworks (e.g., TensorFlow) is a plus.\n",
    "Excellent analytical and problem-solving skills, with a keen eye for detail in visual data and model outputs.\n",
    "Strong communication and teamwork skills, with the ability to articulate technical concepts clearly.\n",
    "A strong desire to learn, adapt, and contribute in a fast-paced environment focused on innovation.\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b10bcae",
   "metadata": {},
   "source": [
    "**Working with Job Description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b26704fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'AI Intern', 'company': None, 'location': None, 'summary': \"We're looking for enthusiastic and talented AI Interns passionate about coding to join our team. This internship offers a unique opportunity to gain hands-on experience by working on real-world projects, contributing to innovative solutions. You will play a crucial role in developing advanced AI solutions from data preparation to model deployment.\", 'responsibilities': ['Data Preparation & Annotation: Assist in collecting, cleaning, preprocessing, and annotating large datasets. This will involve supporting robust OCR and HTR capabilities.', 'Model Experimentation & Evaluation: Conduct experiments to test, evaluate, and fine-tune AI models for accuracy, performance, and scalability.', 'Information Extraction & Analysis: Contribute to the development and testing of features for highly accurate multilingual information extraction, retrieval, summarization, and enhanced pattern recognition from diverse, unstructured government documents.', 'Large Language Model (LLM) Support: Support the team in evaluating, fine-tuning, and testing open-source LLMs for performance and suitability, ensuring they deeply understand government-specific terminology, policies, and contextual nuances in both English and Indian languages.', 'Research & Exploration: Research the latest advancements, architectures, and techniques', 'Prototyping & Implementation: Help in building prototypes and integrating AI components, including those for conceptual predictive insights from forecasting models.', 'Experiment with prompt engineering techniques to optimize outputs from generative models.', 'Explore and implement techniques for controlling generated content and ensuring model safety/alignment.', 'Documentation: Maintain clear and concise documentation of experiments, model development processes, and results.', 'Collaboration: Actively participate in team discussions, brainstorm new ideas, and collaborate with cross-functional teams to align AI solutions with business objectives.'], 'required_skills': ['Strong foundational understanding of core AI and Machine Learning concepts and algorithms', 'Proficiency in at least one programming language, preferably Python'], 'preferred_skills': ['Specific interest in Natural Language Processing (NLP) and Large Language Models (LLMs)', 'Familiarity with deep learning frameworks (e.g., TensorFlow)', 'Excellent analytical and problem-solving skills, with a keen eye for detail in visual data and model outputs', 'Strong communication and teamwork skills, with the ability to articulate technical concepts clearly', 'A strong desire to learn, adapt, and contribute in a fast-paced environment focused on innovation'], 'education_requirements': \"Currently pursuing or recently completed a Bachelor's or Master's degree in Computer Science, Data Science, Artificial Intelligence, Machine Learning from a Tier 1 or Tier-2 Colleges / Autonomous Institutions.\", 'experience_level': 'Intern', 'Else': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "\n",
    "# ---------- 1. Prompt ----------\n",
    "job_jd_extraction_template = \"\"\"\n",
    "You are a resume-assistant that extracts structured data from job descriptions.\n",
    "\n",
    "Return ONLY valid JSON with these keys:\n",
    "- title                       (string or null)\n",
    "- company                     (string or null)\n",
    "- location                    (string or null)\n",
    "- summary                     (string)\n",
    "- responsibilities            (string[])\n",
    "- required_skills             (string[])\n",
    "- preferred_skills            (string[])\n",
    "- education_requirements      (string or null)\n",
    "- experience_level            (string or null)\n",
    "- Else                       (string or null)\n",
    "\n",
    "If a field is missing, use null or an empty list. In description, there can be multiple paragraphs, so you should extract the relevant information from the entire text and sometimes keys for JSON file will have synonyms or different names, so you should extract the relevant information from the entire text and sometimes keys for JSON file will have synonyms or different names.\n",
    "\n",
    "Job description:\n",
    "\\\"\\\"\\\"{description}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"description\"],\n",
    "    template=job_jd_extraction_template.strip()\n",
    ")\n",
    "\n",
    "# ---------- 2. LLM ----------\n",
    "# Gemini-Pro is the general-purpose chat model.\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",      # <- or \"gemini-pro-vision\" etc.\n",
    "    temperature=0.0          # deterministic extraction\n",
    ")\n",
    "\n",
    "# ---------- 3. Chain ----------\n",
    "chain = prompt | llm | SimpleJsonOutputParser()## Structured output of Job Descriptions\n",
    "\n",
    "# ---------- 4. Run ----------\n",
    "\n",
    "result = chain.invoke({\"description\": jd})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd289bb",
   "metadata": {},
   "source": [
    "**Combining Both Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a9ea80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_search_query(job: dict) -> str:\n",
    "    \"\"\"\n",
    "    Turn a structured job-post into a single keyword string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    job : dict\n",
    "        Must contain lists under some or all of these keys:\n",
    "        - \"responsibilities\"\n",
    "        - \"required_skills\"\n",
    "        - \"preferred_skills\"\n",
    "        Everything else is ignored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Comma-separated list with duplicates removed, e.g.\n",
    "        \"Python, TensorFlow, Data preparation, NLP, LLM fine-tuning\"\n",
    "    \"\"\"\n",
    "    # Collect lists; if the key is missing fall back to an empty list\n",
    "    resp    = job.get(\"responsibilities\", [])\n",
    "    req     = job.get(\"required_skills\", [])\n",
    "    pref    = job.get(\"preferred_skills\", [])\n",
    "\n",
    "    # Flatten + deduplicate while preserving order\n",
    "    seen, parts = set(), []\n",
    "    for item in resp + req + pref:\n",
    "        if isinstance(item, str) and item not in seen:\n",
    "            seen.add(item)\n",
    "            parts.append(item)\n",
    "\n",
    "    return \", \".join(parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7ef7e",
   "metadata": {},
   "source": [
    "**MULTI QuereyRETRIVER to exrtact info from Vector DATABASE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dc71191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Skills and Competencies\n",
      "\n",
      "3.1 Skills Summary\n",
      "\n",
      "Programming Languages:Python(3+yrs), C++(3+ yrs), SQL, Matlab\n",
      "ML/NLP Frameworks: TensorFlow, PyTorch, Pandas, Scikit-learn, RAGs\n",
      "VS Code, Google Colab, Hugging Face, LangChain\n",
      "Tools:\n",
      "Power BI, Streamlit(2+yrs), Cadence(2+yrs), Arduino\n",
      "Other:\n",
      "\n",
      "Projects\n",
      "\n",
      "• Transformer Language Model:\n",
      "\n",
      "◦ Implemented a GPT-style transformer-2.2 million parameters from scratch in PyTorch for autoregressive text\n",
      "\n",
      "generation.\n",
      "\n",
      "◦ Designed with Multi-head self-attention (6 heads), residual connections, and achieving a validation perplexity approx\n",
      "\n",
      "10 over 5000 iterations.\n",
      "[Document(id='f0cc6b45-9081-4566-afb2-ed20fef78dfa', metadata={}, page_content='Skills and Competencies\\n\\n3.1 Skills Summary\\n\\nProgramming Languages:Python(3+yrs), C++(3+ yrs), SQL, Matlab\\nML/NLP Frameworks: TensorFlow, PyTorch, Pandas, Scikit-learn, RAGs\\nVS Code, Google Colab, Hugging Face, LangChain\\nTools:\\nPower BI, Streamlit(2+yrs), Cadence(2+yrs), Arduino\\nOther:\\n\\nProjects\\n\\n• Transformer Language Model:\\n\\n◦ Implemented a GPT-style transformer-2.2 million parameters from scratch in PyTorch for autoregressive text\\n\\ngeneration.\\n\\n◦ Designed with Multi-head self-attention (6 heads), residual connections, and achieving a validation perplexity approx\\n\\n10 over 5000 iterations.'), Document(id='bbde7a6e-8f81-4336-a310-1f7cf58edb8d', metadata={}, page_content='Methods, Results, and Conclusion.\\n\\n◦ Trained on the SkimLit dataset to enhance literature review automation.\\n\\n◦ Combined BiDirectional LSTM for character-level vectorization with a Universal Sentence Encoder, improving\\n\\ncontextual understanding.\\n\\n◦ Implemented dropout layers to prevent overfitting, achieving an accuracy of 81.2%.\\n\\nVolunteer Experience\\n\\n• CO-Coordinator of Astronomy and Physics Society of College: Organised educational workshops and community\\nevents for the Astronomy and Physics Society, engaging over 200 participants in hands-on space exploration activities.'), Document(id='79f557c7-f00d-45e2-88b3-32fcd3a08352', metadata={}, page_content='• Summer Intern\\n\\nMachine Learning Intern\\n\\nIIITDM Jabalpur\\nMay 2024 - July 2024\\n\\n◦ Sign Language Detection Model: Developed a Convolutional Neural Network (CNN) model for real-time sign\\n\\nlanguage detection using Python and TensorFlow via collaborating with a team. Utilised Mediapipe and optimised model\\nperformance by fine-tuning hyperparameters to reduce computation time by 30%.\\n\\nSkills and Competencies\\n\\n3.1 Skills Summary'), Document(id='ba8aed15-7310-4a86-af0e-3f471fbde677', metadata={}, page_content='10 over 5000 iterations.\\n\\n◦ Tech Stack: PyTorch, Pandas, inspired by nanoGPT and Attention Is All You Need.\\n\\n• Feast-AI: APP\\n\\n◦ Achieved 85% accuracy on the DeepFood dataset, surpassing the original paper’s 77.4%, with a training time of ˜60\\n\\nmin compared to their 2-3 days.\\n\\n◦ A Food classification model capable of accurately identifying 101 types of food items.\\n\\n◦ Optimized computational efficiency by implementing mixed precision (float16 + float32).\\n\\n• EZE-Paragrapher:\\n\\n◦ Constructed an NLP classification system for research abstracts, enabling precise categorisation into Objective,'), Document(id='4216aedb-186b-4ccb-a7c7-c2107c1beaef', metadata={}, page_content='Varanasi, India\\nApril 2020 - July 2021\\n\\nProfessor Aparajita Ojha\\nMay 2025 - Ongoing\\n\\n◦ Cancer Classification Using Gene Expression Data: Utilising a GenAI, Vision Models and DeepInsight framework\\n\\nto develop a pipeline for Cancer prediction from gene expression data.\\n\\n• Research Intern\\n\\nDr. Deep Prakash Samjdar\\nOct 2024 - May 2025\\n◦ Performance Analysis of Sn-based Perovskite Materials: Built ML models to predict solar cell metrics (Voc, Jsc,\\n\\nData Analyst Intern\\n\\nPCE, FF) of 11 materials, conducted EDA to uncover performance trends supporting next-gen solar cell research.\\n\\n• Summer Intern'), Document(id='d23afbbf-a374-46ac-8750-342ca2b0ccb0', metadata={}, page_content='• CAMPUS AMBASSADOR: I was also the Campus Ambassador of my college in Techkriti’24, IIT Kanpur.'), Document(id='21ad31cc-7254-417e-8357-d94d02ecfd4b', metadata={}, page_content='ALOK RAI\\nMobile: +91-9151348969\\n\\nEducation\\n\\nEmail: 22bec010@iiitdmj.ac.in\\nLinkedIn: www.linkedin.com/in/alok-rai158\\nGitHub: github.com/ALOK158\\n\\n• Indian Institute of Information Technology, Design and Manufacturing\\n\\nBachelor of Technology - Electronics and Communication; CPI: 7.9\\n\\n• Sant Atulanand Convent School\\n\\n12th - 93.3%\\nExperience\\n\\n• Summer Intern\\n\\nMachine Learning Intern\\n\\nJabalpur, India\\nNov 2022 - July 2026\\n\\nVaranasi, India\\nApril 2020 - July 2021\\n\\nProfessor Aparajita Ojha\\nMay 2025 - Ongoing')]\n"
     ]
    }
   ],
   "source": [
    "# --- 0. prerequisites ---------------------------------------------------------\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# --- 1. base retriever --------------------------------------------------------\n",
    "# pull (for example) the 2 most similar chunks for *each* query\n",
    "base_retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 7}\n",
    ")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI   # make sure this import matches your package version\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",   # <- correct kwarg\n",
    "    temperature=0.2,\n",
    ")\n",
    "# --- 3. wrap in a Multi-Query retriever --------------------------------------\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "        retriever   = base_retriever,   # your existing retriever\n",
    "        llm         = llm\n",
    ")\n",
    "\n",
    "# 4. build search query from job post\n",
    "search_query = build_search_query(result)\n",
    "\n",
    "docs =multi_query_retriever.get_relevant_documents(search_query)\n",
    "\n",
    "# --- 4. use it like any other retriever --------------------------------------\n",
    "\n",
    "print(len(docs), docs[0].page_content)\n",
    "print(docs)\n",
    "\n",
    "# or plug it straight into a QA / conversation chain\n",
    "# from langchain.chains import ConversationalRetrievalChain\n",
    "# qa_chain = ConversationalRetrievalChain.from_llm(llm, multi_query_retriever)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df03dbf",
   "metadata": {},
   "source": [
    "**Comparing the results after extraction info from Resume and the Job Description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3aca7a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"matches\": [\n",
      "    \"The resume shows proficiency in Python and experience with TensorFlow, both required and preferred skills.\",\n",
      "    \"The candidate has experience with NLP, including building a transformer language model and working on a food classification project, aligning with the preferred interest in NLP and LLMs.\",\n",
      "    \"The resume demonstrates experience in model development, evaluation, and optimization, including hyperparameter tuning and techniques to reduce computation time.\",\n",
      "    \"The candidate's projects showcase experience in data preprocessing, model building, and performance analysis, which are relevant to the internship responsibilities.\"\n",
      "  ],\n",
      "  \"gaps\": [\n",
      "    \"The resume does not explicitly mention experience with large language models (LLMs) beyond building a transformer model.  The job description emphasizes LLM support and understanding of government-specific terminology, which is not evident in the resume.\",\n",
      "    \"There is no mention of experience with multilingual information extraction or working with unstructured government documents, which are key responsibilities.\",\n",
      "    \"The resume lacks explicit demonstration of skills in prompt engineering, model safety/alignment, or experience with OCR/HTR.\",\n",
      "    \"The candidate's education is not explicitly stated as being from a Tier 1 or Tier 2 college, a requirement of the job description.\"\n",
      "  ],\n",
      "  \"overall_fit\": \"While the candidate possesses some relevant skills and project experience, the lack of specific experience with LLMs, multilingual information extraction, and government-specific data, along with unconfirmed educational institution tier, makes them a poor fit for this AI internship.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1-- LLM instance\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
    "\n",
    "# 2-- prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a career-matching assistant. \"\n",
    "     \"Use ONLY the resume snippets provided to judge the fit.\"),\n",
    "    (\"user\", \"Job description (JSON):\\n{job_json}\"),\n",
    "    (\"user\", \"Resume snippets:\\n{snippets}\"),\n",
    "    (\"user\",\n",
    "     \"Return a JSON with keys:\\n\"\n",
    "     \"  - matches  (bullet points where the resume meets the job)\\n\"\n",
    "     \"  - gaps     (bullet points where the resume is missing something)\\n\"\n",
    "     \"  - overall_fit (one-sentence conclusion)-- be very strict in your assessment!\"),\n",
    "])\n",
    "\n",
    "# 3-- combine template + LLM  -> runnable chain\n",
    "chain = prompt | llm          # equivalent to RunnableSequence(prompt, llm)\n",
    "\n",
    "# 4-- variables you collected earlier\n",
    "variables = {\n",
    "    \"job_json\": result,          # dict or JSON string\n",
    "    \"snippets\": docs                # \"\\n---\\n\".join(d.page_content for d in docs)\n",
    "}\n",
    "\n",
    "# 5-- run the chain\n",
    "answer = chain.invoke(variables)        # returns an LLM message object\n",
    "print(answer.content)                   # or just `print(answer)` depending on version\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
